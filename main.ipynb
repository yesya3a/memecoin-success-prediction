{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import Bunch\n",
    "import joblib\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    tokens_path: str = \"data/tokens.csv\"\n",
    "    comments_path: str = \"data/comments.csv\"\n",
    "    images_dir: str = \"data/images\"     \n",
    "    test_size: float = 0.15\n",
    "    val_size: float = 0.15\n",
    "    random_state: int = 42\n",
    "    min_comments_for_sentiment: int = 1  \n",
    "\n",
    "\n",
    "CFG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53961d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_vader_downloaded():\n",
    "    try:\n",
    "        _ = SentimentIntensityAnalyzer()\n",
    "    except LookupError:\n",
    "        nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "def load_data(cfg: Config) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    tokens = pd.read_csv(cfg.tokens_path)\n",
    "    comments = pd.read_csv(cfg.comments_path)\n",
    "\n",
    "    required_token_cols = [\"token_id\", \"description\", \"max_mcap\", \"market_entry_time\"]\n",
    "    required_comment_cols = [\"token_id\", \"user_id\", \"text\"]\n",
    "\n",
    "    for c in required_token_cols:\n",
    "        if c not in tokens.columns:\n",
    "            raise ValueError(f\"tokens.csv is missing column: {c}\")\n",
    "\n",
    "    for c in required_comment_cols:\n",
    "        if c not in comments.columns:\n",
    "            raise ValueError(f\"comments.csv is missing column: {c}\")\n",
    "\n",
    "    return tokens, comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18da862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_labels(tokens: pd.DataFrame) -> pd.Series:\n",
    "    tokens = tokens.copy()\n",
    "    tokens[\"max_mcap\"] = pd.to_numeric(tokens[\"max_mcap\"], errors=\"coerce\")\n",
    "    median_mcap = tokens[\"max_mcap\"].median()\n",
    "    labels = (tokens[\"max_mcap\"] >= median_mcap).astype(int)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def build_text_features(tokens: pd.DataFrame) -> Tuple[np.ndarray, TfidfVectorizer]:\n",
    "    descriptions = tokens[\"description\"].fillna(\"\").astype(str)\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=1000,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=\"english\",\n",
    "        lowercase=True\n",
    "    )\n",
    "    X_text = vectorizer.fit_transform(descriptions)\n",
    "    return X_text.toarray(), vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2723db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_comment_sentiment(comments: pd.DataFrame) -> pd.DataFrame:\n",
    "    ensure_vader_downloaded()\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "    comments = comments.copy()\n",
    "    comments[\"text\"] = comments[\"text\"].fillna(\"\").astype(str)\n",
    "    scores = comments[\"text\"].apply(lambda t: sia.polarity_scores(t)[\"compound\"])\n",
    "    comments[\"sent_score\"] = scores\n",
    "\n",
    "    grouped = comments.groupby(\"token_id\").agg(\n",
    "        n_comments=(\"text\", \"count\"),\n",
    "        n_users=(\"user_id\", pd.Series.nunique),\n",
    "        sent_mean=(\"sent_score\", \"mean\"),\n",
    "        sent_std=(\"sent_score\", \"std\"),\n",
    "        sent_pos_ratio=(\"sent_score\", lambda s: (s > 0.05).mean()),\n",
    "        sent_neg_ratio=(\"sent_score\", lambda s: (s < -0.05).mean())\n",
    "    ).reset_index()\n",
    "\n",
    "    grouped[\"sent_std\"] = grouped[\"sent_std\"].fillna(0.0)\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def build_community_features(tokens: pd.DataFrame,\n",
    "                             comments: pd.DataFrame) -> Tuple[np.ndarray, pd.DataFrame]:\n",
    "    agg = compute_comment_sentiment(comments)\n",
    "    merged = tokens[[\"token_id\"]].merge(agg, on=\"token_id\", how=\"left\")\n",
    "\n",
    "    community_cols = [\"n_comments\", \"n_users\", \"sent_mean\", \"sent_std\",\n",
    "                      \"sent_pos_ratio\", \"sent_neg_ratio\"]\n",
    "    merged[community_cols] = merged[community_cols].fillna(0.0)\n",
    "\n",
    "    return merged[community_cols].values, merged[[\"token_id\"] + community_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1ee739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcac84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_financial_features(tokens: pd.DataFrame) -> Tuple[np.ndarray, List[str], StandardScaler]:\n",
    "    feats = tokens[[\"market_entry_time\", \"max_mcap\"]].copy()\n",
    "    feats = feats.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    feats = feats.fillna(feats.median())\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_fin = scaler.fit_transform(feats)\n",
    "\n",
    "    return X_fin, list(feats.columns), scaler\n",
    "\n",
    "\n",
    "def build_image_features(tokens: pd.DataFrame, cfg: Config) -> Tuple[np.ndarray, List[str]]:\n",
    "    n = len(tokens)\n",
    "    d_img = 32\n",
    "    X_img = np.zeros((n, d_img), dtype=float)\n",
    "    img_cols = [f\"img_feat_{i}\" for i in range(d_img)]\n",
    "    return X_img, img_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X: np.ndarray, y: np.ndarray,\n",
    "                         cfg: Config) -> Dict[str, np.ndarray]:\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=cfg.test_size,\n",
    "        random_state=cfg.random_state,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    val_ratio = cfg.val_size / (1.0 - cfg.test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val,\n",
    "        test_size=val_ratio,\n",
    "        random_state=cfg.random_state,\n",
    "        stratify=y_train_val\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        X_val=X_val, y_val=y_val,\n",
    "        X_test=X_test, y_test=y_test\n",
    "    )\n",
    "\n",
    "\n",
    "def train_and_evaluate_models(splits: Dict[str, np.ndarray]) -> Bunch:\n",
    "    X_train, y_train = splits[\"X_train\"], splits[\"y_train\"]\n",
    "    X_val, y_val = splits[\"X_val\"], splits[\"y_val\"]\n",
    "    X_test, y_test = splits[\"X_test\"], splits[\"y_test\"]\n",
    "\n",
    "    models = {\n",
    "        \"logreg\": LogisticRegression(max_iter=500, n_jobs=-1),\n",
    "        \"rf\": RandomForestClassifier(\n",
    "            n_estimators=300, max_depth=None, random_state=CFG.random_state\n",
    "        ),\n",
    "        \"gb\": GradientBoostingClassifier(random_state=CFG.random_state),\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    best_model_name = None\n",
    "    best_val_auc = -np.inf\n",
    "    best_model = None\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        val_proba = model.predict_proba(X_val)[:, 1]\n",
    "        val_pred = (val_proba >= 0.5).astype(int)\n",
    "        val_acc = accuracy_score(y_val, val_pred)\n",
    "        val_f1 = f1_score(y_val, val_pred)\n",
    "        try:\n",
    "            val_auc = roc_auc_score(y_val, val_proba)\n",
    "        except ValueError:\n",
    "            val_auc = np.nan\n",
    "\n",
    "        print(f\"\\n[{name}] Validation: \"\n",
    "              f\"Acc={val_acc:.3f}, F1={val_f1:.3f}, AUC={val_auc:.3f}\")\n",
    "\n",
    "        results.append(dict(\n",
    "            model=name,\n",
    "            split=\"val\",\n",
    "            acc=val_acc,\n",
    "            f1=val_f1,\n",
    "            auc=val_auc\n",
    "        ))\n",
    "\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            best_model_name = name\n",
    "            best_model = model\n",
    "\n",
    "    test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    test_pred = (test_proba >= 0.5).astype(int)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    test_f1 = f1_score(y_test, test_pred)\n",
    "    test_auc = roc_auc_score(y_test, test_proba)\n",
    "\n",
    "    print(f\"\\nBest model on validation: {best_model_name}\")\n",
    "    print(f\"[{best_model_name}] Test: \"\n",
    "          f\"Acc={test_acc:.3f}, F1={test_f1:.3f}, AUC={test_auc:.3f}\")\n",
    "\n",
    "    return Bunch(\n",
    "        best_model=best_model,\n",
    "        best_model_name=best_model_name,\n",
    "        val_results=results,\n",
    "        test_metrics=dict(acc=test_acc, f1=test_f1, auc=test_auc)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Loading data...\")\n",
    "    tokens, comments = load_data(CFG)\n",
    "\n",
    "    print(\"Building label (HighCap / LowCap)...\")\n",
    "    y = build_labels(tokens).values\n",
    "\n",
    "    print(\"Building text features...\")\n",
    "    X_text, tfidf_vec = build_text_features(tokens)\n",
    "\n",
    "    print(\"Building community features...\")\n",
    "    X_comm, _ = build_community_features(tokens, comments)\n",
    "\n",
    "    print(\"Building financial features...\")\n",
    "    X_fin, fin_cols, fin_scaler = build_financial_features(tokens)\n",
    "\n",
    "    print(\"Building image features (placeholder zeros)...\")\n",
    "    X_img, img_cols = build_image_features(tokens, CFG)\n",
    "\n",
    "    print(\"Concatenating multimodal features...\")\n",
    "    X_multi = np.concatenate([X_text, X_comm, X_fin, X_img], axis=1)\n",
    "\n",
    "    print(f\"Shape of multimodal feature matrix: {X_multi.shape}\")\n",
    "\n",
    "    print(\"Splitting train/val/test...\")\n",
    "    splits = train_val_test_split(X_multi, y, CFG)\n",
    "\n",
    "    print(\"Training and evaluating models...\")\n",
    "    results = train_and_evaluate_models(splits)\n",
    "\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    model_path = os.path.join(\"models\", f\"{results.best_model_name}_multimodal.joblib\")\n",
    "    joblib.dump(dict(\n",
    "        model=results.best_model,\n",
    "        tfidf=tfidf_vec,\n",
    "        fin_scaler=fin_scaler,\n",
    "        config=CFG\n",
    "    ), model_path)\n",
    "\n",
    "    print(f\"\\nBest model saved to: {model_path}\")\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
